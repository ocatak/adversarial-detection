{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_All_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTbKepqbUv9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9991bf13-848a-44db-ccac-3216996a385b"
      },
      "source": [
        "!pip install foolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting foolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ff/1ba817ad9aa7c2ca28fb809d64939bee7311e3e62fdd87c4011232c4640e/foolbox-3.3.1-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 23.1MB/s \n",
            "\u001b[?25hCollecting GitPython>=3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 49.6MB/s \n",
            "\u001b[?25hCollecting eagerpy==0.29.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/07/54994565da4fc5a4840d3a434fb9bf3835b4a4e68c931ccfcc327d568f95/eagerpy-0.29.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.19.5)\n",
            "Collecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (56.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (3.0.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: smmap, gitdb, GitPython, eagerpy, requests, foolbox\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed GitPython-3.1.17 eagerpy-0.29.0 foolbox-3.3.1 gitdb-4.0.7 requests-2.25.1 smmap-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCH3lEpvU2BP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875d9b77-ebdc-49e8-f0f7-76b1bf747c35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zItb42WVU37J"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import foolbox as fb\n",
        "from foolbox import PyTorchModel, accuracy, samples\n",
        "from foolbox.attacks import LinfPGD,LinfBasicIterativeAttack,LinfFastGradientAttack,L2CarliniWagnerAttack,LinfDeepFoolAttack,L2DeepFoolAttack,L2PGD\n",
        "from time import gmtime, strftime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import multiprocessing as mp\n",
        "from torch.distributions import Categorical\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HctfhdgU6c9"
      },
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/checkpointCIFAR10'):\n",
        "    os.makedirs('/content/gdrive/MyDrive/checkpointCIFAR10')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzcIzIQUVBoC"
      },
      "source": [
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mean = torch.Tensor(mean)\n",
        "        self.std = torch.Tensor(std)\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeB0TkkqVag6"
      },
      "source": [
        "class LeNet_dropout(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet_dropout, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "        self.drop_layer = nn.Dropout(p=0.5)\n",
        "        self.drop_layer_conv = nn.Dropout2d(p=0.5)\n",
        "\n",
        "    def last_hidden_layer_output(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x),inplace=True)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x),inplace=True), kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv3(x),inplace=True)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x),inplace=True), kernel_size=2, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv5(x),inplace=True)\n",
        "        x = self.drop_layer_conv(F.max_pool2d(F.relu(self.conv6(x),inplace=True), kernel_size=2, stride=2))\n",
        "\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.drop_layer(F.relu(self.fc1(x)))\n",
        "        x = self.drop_layer(F.relu(self.fc2(x)))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.last_hidden_layer_output(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KZrId2yVeYB"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MLP,self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "\n",
        "      nn.Linear(256, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 10),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQDyTYBAWMsm"
      },
      "source": [
        "\n",
        "def train(model, opt, epoch):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    lr = opt.param_groups[0]['lr']\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)] lr: {}\\tLoss: {:.6f}'\n",
        "                  .format(epoch, batch_idx * len(data),\n",
        "                          len(train_loader.dataset),\n",
        "                          100. * batch_idx / len(train_loader),\n",
        "                          lr, loss.data))\n",
        "\n",
        "def test(model):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(F.log_softmax(output, dim=1), target, size_average=False).data# sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def mcdropout_test(model):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    enable_dropout(model)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    T = 50\n",
        "\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output_list = []\n",
        "\n",
        "        for i in range(T):\n",
        "            output_list.append(torch.unsqueeze(model(data), 0))\n",
        "\n",
        "        output_mean = torch.cat(output_list, 0).mean(0)\n",
        "        test_loss += F.nll_loss(F.log_softmax(output_mean, dim=1), target, size_average=False).data  # sum up batch loss\n",
        "        pred = output_mean.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nMC Dropout Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def enable_dropout(model):\n",
        "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
        "    for m in model.modules():\n",
        "        if m.__class__.__name__.startswith('Dropout'):\n",
        "            m.train()\n",
        "\n",
        "def noise(x, eps, clip_min, clip_max):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    eta = torch.FloatTensor(*x.shape).normal_(mean=0,std=eps)\n",
        "    eta = eta.to(device)\n",
        "    adv_x = x + eta\n",
        "    if clip_min is not None and clip_max is not None:\n",
        "        adv_x = torch.clamp(adv_x, min=clip_min, max=clip_max)\n",
        "    return adv_x\n",
        "\n",
        "def predict_uncertainties(model, image, T=50):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    image = image.to(device)\n",
        "\n",
        "    #torch.manual_seed(2)\n",
        "\n",
        "    image = image.detach()\n",
        "    item_count = image.shape[0]\n",
        "\n",
        "    enable_dropout(model)\n",
        "    model.train()\n",
        "\n",
        "    dropout_predictions = torch.zeros([T, item_count, 10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        enable_dropout(model)\n",
        "        model.train()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "\n",
        "        output_prob = F.softmax(output, dim=1) #shape is 1x10 if item_count is 1 (only one image in input batch)\n",
        "        dropout_predictions[t] = output_prob\n",
        "\n",
        "    #dropout_predictions is of shape 50xitem_countx10\n",
        "\n",
        "    # print(\"dropout predictions shape\", dropout_predictions.shape)\n",
        "\n",
        "    mean = torch.mean(dropout_predictions, dim=0)\n",
        "\n",
        "    entropy = Categorical(probs=mean).entropy()\n",
        "\n",
        "    pred_mean = mean\n",
        "\n",
        "    aleatoric = torch.zeros([item_count,10,10])\n",
        "    epistemic = torch.zeros([item_count,10,10])\n",
        "\n",
        "    for t in range(T):\n",
        "\n",
        "        pred_t = dropout_predictions[t]\n",
        "\n",
        "        aleatoric += torch.diag_embed(pred_t, offset=0, dim1=-2, dim2=-1) - pred_t[:, :, None] @ pred_t[:, None, :]\n",
        "        epistemic += (pred_t - pred_mean)[:, :, None] @ (pred_t - pred_mean)[:, None, :]\n",
        "\n",
        "    aleatoric = aleatoric / T #both of them are of shape item_count x 10x10\n",
        "    epistemic = epistemic / T #both of them are of shape item_count x 10x10\n",
        "\n",
        "    # print(\"aleatoric.shape\", aleatoric.shape)\n",
        "    # print(\"aleatoric.diag.shape\", torch.diagonal(aleatoric, 0, dim1=-2, dim2=-1).shape)\n",
        "\n",
        "    aleatoric = torch.diagonal(aleatoric, 0, dim1=-2, dim2=-1)\n",
        "    epistemic = torch.diagonal(epistemic, 0, dim1=-2, dim2=-1)\n",
        "\n",
        "    aleatoric = torch.mean(aleatoric,1,True)\n",
        "    epistemic = torch.mean(epistemic, 1, True)\n",
        "\n",
        "    scibilic = epistemic / aleatoric\n",
        "\n",
        "    scibilic[torch.isnan(scibilic)] = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return aleatoric.transpose_(0, 1)[0], epistemic.transpose_(0, 1)[0], scibilic.transpose_(0, 1)[0], entropy\n",
        "\n",
        "def calculate_distance(model, predictions, last_hidden_layer_outs):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = []\n",
        "\n",
        "    for z in range(last_hidden_layer_outs.shape[0]):\n",
        "\n",
        "        hidden_tensor = torch.from_numpy(last_hidden_layer_outs[z])\n",
        "\n",
        "        hidden_tensor = hidden_tensor.to(device)\n",
        "\n",
        "        hidden_tensor = torch.unsqueeze(hidden_tensor, 0)\n",
        "\n",
        "        total.append(F.softmax(model(hidden_tensor) / 1, dim=1)[0][predictions[z].item()])\n",
        "\n",
        "    return torch.Tensor(total)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLk3qfwjXTER"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "learning_rate = 0.001\n",
        "epoch = 50\n",
        "\n",
        "model_dropout = LeNet_dropout()\n",
        "model_dropout = model_dropout.to(device)\n",
        "\n",
        "optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=learning_rate)\n",
        "\n",
        "norm = Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poL7mwGRWR8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ed619e-6231-4aa9-cc8b-ed8ada663569"
      },
      "source": [
        "\n",
        "print(\"Press 0, 1, 2 , 3 , 4 , 5 :\\ntrain mode (0)\\ntest set uncertainty metrics for correct and wrong predictions (1)\\nPrepare Last Hidden Layer Outputs (2)\\nTrain MLP (3)\\nPrepare Data (4)\\nPlot Performances (5)\\n\")\n",
        "\n",
        "input_a = int(input())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Press 0, 1, 2 , 3 , 4 , 5 :\n",
            "train mode (0)\n",
            "test set uncertainty metrics for correct and wrong predictions (1)\n",
            "Prepare Last Hidden Layer Outputs (2)\n",
            "Train MLP (3)\n",
            "Prepare Data (4)\n",
            "Plot Performances (5)\n",
            "\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NltwGLsJWVII"
      },
      "source": [
        "if input_a == 0:\n",
        "    \n",
        "    #transform_train = transforms.Compose(\n",
        "     #   [transforms.RandomCrop(32, padding=4),\n",
        "      #   transforms.RandomHorizontalFlip(),\n",
        "       #  transforms.ToTensor(),\n",
        "       #  transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
        "\n",
        "    transform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
        "\n",
        "    train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
        "\n",
        "    print ('Train Lenet with dropout at all layer')\n",
        "    for epoch in range(1, epoch + 1):\n",
        "        train(model_dropout, optimizer_dropout, epoch)\n",
        "    print(\"Test Set results of dropout model\")\n",
        "    test(model_dropout)\n",
        "    #print(\"MC Dropout Test Results of dropout model\")\n",
        "    #mcdropout_test(model_dropout)\n",
        "\n",
        "    print('Save /content/gdrive/MyDrive/checkpointCIFAR10/' + 'LeNet_dropout' + '.pth.tar')\n",
        "    state = {'state_dict': model_dropout.state_dict()}\n",
        "    filename = '/content/gdrive/MyDrive/checkpointCIFAR10/' + 'LeNet_dropout' + '.pth.tar'\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5msR8dxWjTj"
      },
      "source": [
        "if input_a == 1:\n",
        "\n",
        "\n",
        "    transform_test = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
        "\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_dropout.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    model_dropout.eval()\n",
        "    model_dropout = model_dropout.to(device)\n",
        "\n",
        "    print(\"Beginning time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    first_time = datetime.datetime.now()\n",
        "\n",
        "    al_clean_tensor_corrects = torch.empty(0)\n",
        "    ep_clean_tensor_corrects = torch.empty(0)\n",
        "    sc_clean_tensor_corrects = torch.empty(0)\n",
        "    ent_clean_tensor_corrects = torch.empty(0)\n",
        "\n",
        "    al_clean_tensor_wrongs = torch.empty(0)\n",
        "    ep_clean_tensor_wrongs = torch.empty(0)\n",
        "    sc_clean_tensor_wrongs = torch.empty(0)\n",
        "    ent_clean_tensor_wrongs = torch.empty(0)\n",
        "\n",
        "    a = 0\n",
        "\n",
        "    for test_images, test_labels in test_loader:\n",
        "\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        model_dropout.eval()\n",
        "        sample_image = test_images\n",
        "        sample_label = test_labels\n",
        "        outputs = model_dropout(test_images)\n",
        "        corrects = (outputs.max(dim=1)[1] == test_labels)\n",
        "        wrongs = (outputs.max(dim=1)[1] != test_labels)\n",
        "\n",
        "        sample_image_corrects = sample_image[corrects]\n",
        "        sample_label_corrects = sample_label[corrects]\n",
        "\n",
        "        sample_image_wrongs = sample_image[wrongs]\n",
        "        sample_label_wrongs = sample_label[wrongs]\n",
        "\n",
        "\n",
        "        al_clean_corrects, ep_clean_corrects, sc_clean_corrects, ent_clean_corrects = predict_uncertainties(model_dropout, sample_image_corrects, 50)\n",
        "\n",
        "        al_clean_tensor_corrects = torch.cat([al_clean_tensor_corrects, al_clean_corrects])\n",
        "        ep_clean_tensor_corrects = torch.cat([ep_clean_tensor_corrects, ep_clean_corrects])\n",
        "        sc_clean_tensor_corrects = torch.cat([sc_clean_tensor_corrects, sc_clean_corrects])\n",
        "        ent_clean_tensor_corrects = torch.cat([ent_clean_tensor_corrects, ent_clean_corrects])\n",
        "\n",
        "        if sample_image_wrongs.shape[0] != 0:\n",
        "\n",
        "            al_clean_wrongs, ep_clean_wrongs, sc_clean_wrongs, ent_clean_wrongs = predict_uncertainties(model_dropout, sample_image_wrongs, 50)\n",
        "\n",
        "            al_clean_tensor_wrongs = torch.cat([al_clean_tensor_wrongs, al_clean_wrongs])\n",
        "            ep_clean_tensor_wrongs = torch.cat([ep_clean_tensor_wrongs, ep_clean_wrongs])\n",
        "            sc_clean_tensor_wrongs = torch.cat([sc_clean_tensor_wrongs, sc_clean_wrongs])\n",
        "            ent_clean_tensor_wrongs = torch.cat([ent_clean_tensor_wrongs, ent_clean_wrongs])\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA FOR CORRECTS....\")\n",
        "    al_clean_tensor_corrects, ep_clean_tensor_corrects, sc_clean_tensor_corrects, ent_clean_tensor_corrects = al_clean_tensor_corrects.numpy(), ep_clean_tensor_corrects.numpy(), sc_clean_tensor_corrects.numpy(), ent_clean_tensor_corrects.numpy()\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA FOR WRONGS...\")\n",
        "    al_clean_tensor_wrongs, ep_clean_tensor_wrongs, sc_clean_tensor_wrongs, ent_clean_tensor_wrongs = al_clean_tensor_wrongs.numpy(), ep_clean_tensor_wrongs.numpy(), sc_clean_tensor_wrongs.numpy(), ent_clean_tensor_wrongs.numpy()\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"\\nMean of the aleatoric uncertainty values for all the errors : \", al_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the aleatoric uncertainty values for all the corrects \", al_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the epistemic uncertainty values for all the errors : \", ep_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the epistemic uncertainty values for all the corrects \", ep_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the scibilic uncertainty values for all the errors : \", sc_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the scibilic uncertainty values for all the corrects \", sc_clean_tensor_corrects.mean())\n",
        "\n",
        "    print(\"\\nMean of the entropy values for all the errors : \", ent_clean_tensor_wrongs.mean())\n",
        "    print(\"Mean of the entropy values for all the corrects \", ent_clean_tensor_corrects.mean())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hciP2_3YXmFk"
      },
      "source": [
        "if input_a == 2:\n",
        "\n",
        "    train_data = datasets.CIFAR10(root='data', train=True, download=False, transform=transforms.ToTensor())\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=False, transform=transforms.ToTensor())\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    norm = Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "    preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261], axis=-3)\n",
        "\n",
        "    model_attack = LeNet_dropout()\n",
        "    ckpt_attack = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_attack.load_state_dict(ckpt_attack['state_dict'])\n",
        "    model_attack.eval()\n",
        "    model_attack = model_attack.to(device)\n",
        "\n",
        "    last_hidden_idx = -4\n",
        "    output_dim = list(model_attack.children())[last_hidden_idx].out_features\n",
        "    print(output_dim)\n",
        "\n",
        "    ################ CLEAN LAST HIDDEN LAYER OUTPUTS ####################\n",
        "    last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "    predss = np.empty((0))\n",
        "    labelss = np.empty((0))\n",
        "\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model_attack(image)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        pred = pred.view_as(label)\n",
        "        predss = np.hstack((predss, pred.detach().cpu().numpy()))\n",
        "        labelss = np.hstack((labelss, label.cpu().numpy()))\n",
        "\n",
        "        last_hidden_layer_outputs = np.vstack(\n",
        "            (last_hidden_layer_outputs, model_attack.last_hidden_layer_output(image).detach().cpu().numpy()))\n",
        "\n",
        "    inds_correct = np.where(predss == labelss)[0]\n",
        "\n",
        "    predss = predss[inds_correct]\n",
        "    labelss = labelss[inds_correct]\n",
        "    last_hidden_layer_outputs = last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ################ ADVERSARIAL LAST HIDDEN LAYER OUTPUTS ####################\n",
        "\n",
        "    adv_last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "\n",
        "    model_attack.eval()\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        attack = LinfBasicIterativeAttack()\n",
        "        fmodel = PyTorchModel(model_attack, bounds=(0, 1))\n",
        "        raw_advs, clipped_advs, success = attack(fmodel, image, label, epsilons=[0.03])\n",
        "        pert = torch.tensor(clipped_advs[0])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            adv_last_hidden_layer_outputs = np.vstack(\n",
        "                (adv_last_hidden_layer_outputs, model_attack.last_hidden_layer_output(pert).cpu().numpy()))\n",
        "\n",
        "    adv_last_hidden_layer_outputs = adv_last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ################ NOSIY LAST HIDDEN LAYER OUTPUTS ####################\n",
        "\n",
        "    noisy_last_hidden_layer_outputs = np.empty((0, output_dim))\n",
        "\n",
        "    model_attack.eval()\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        noisy_image = noise(image, 0.03, 0, 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            noisy_last_hidden_layer_outputs = np.vstack(\n",
        "                (noisy_last_hidden_layer_outputs, model_attack.last_hidden_layer_output(noisy_image).cpu().numpy()))\n",
        "\n",
        "    noisy_last_hidden_layer_outputs = noisy_last_hidden_layer_outputs[inds_correct]\n",
        "\n",
        "    ###############\n",
        "\n",
        "    dig_outputs = {}\n",
        "    dig_outputs_raw = {}\n",
        "    dig_labels = {}\n",
        "    dig_labels_raw = {}\n",
        "    dig_outputs_adv = {}\n",
        "    dig_outputs_adv_raw = {}\n",
        "    dig_outputs_noisy = {}\n",
        "    dig_outputs_noisy_raw = {}\n",
        "\n",
        "    for i in range(10):\n",
        "        inds_i = np.where(predss == i)[0]\n",
        "\n",
        "        dig_outputs_raw[i] = last_hidden_layer_outputs[inds_i]\n",
        "        dummy = dig_outputs_raw[i].copy()\n",
        "\n",
        "        dig_labels_raw[i] = labelss[inds_i]\n",
        "        dummy_labels = dig_labels_raw[i].copy()\n",
        "\n",
        "        dig_outputs_adv_raw[i] = adv_last_hidden_layer_outputs[inds_i]\n",
        "        dummy_adv = dig_outputs_adv_raw[i].copy()\n",
        "\n",
        "        dig_outputs_noisy_raw[i] = noisy_last_hidden_layer_outputs[inds_i]\n",
        "        dummy_noisy = dig_outputs_noisy_raw[i].copy()\n",
        "\n",
        "        rows = dummy.shape[0]\n",
        "\n",
        "        dig_outputs[i] = dummy\n",
        "        dig_labels[i] = dummy_labels\n",
        "        dig_outputs_adv[i] = dummy_adv\n",
        "        dig_outputs_noisy[i] = dummy_noisy\n",
        "\n",
        "    for i in range(10):\n",
        "        filename = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_' + str(i) + '.npy'\n",
        "        np.save(filename, dig_outputs[i])\n",
        "\n",
        "        filename2 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_labels_' + str(i) + '.npy'\n",
        "        np.save(filename2, dig_labels[i])\n",
        "\n",
        "        filename3 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_adv_' + str(i) + '.npy'\n",
        "        np.save(filename3, dig_outputs_adv[i])\n",
        "\n",
        "        filename4 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_noisy' + str(i) + '.npy'\n",
        "        np.save(filename4, dig_outputs_noisy[i])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqw6NJdZ3AA"
      },
      "source": [
        "if input_a == 3:\n",
        "\n",
        "    my_mlp_model = MLP()\n",
        "    my_mlp_model = my_mlp_model.to(device)\n",
        "\n",
        "    model_attack_new = LeNet_dropout()\n",
        "    ckpt_attack_new = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_attack_new.load_state_dict(ckpt_attack_new['state_dict'])\n",
        "    model_attack_new.eval()\n",
        "    model_attack_new = model_attack_new.to(device)\n",
        "\n",
        "    dig_labels = {}\n",
        "    dig_outputs = {}\n",
        "    dig_outputs_adv = {}\n",
        "    dig_outputs_noisy = {}\n",
        "\n",
        "    data = np.empty((0, 256))\n",
        "    labels = np.empty((0, 1))\n",
        "\n",
        "    for i in range(10):\n",
        "        filename = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_' + str(i) + '.npy'\n",
        "        dig_outputs[i] = np.load(filename)\n",
        "\n",
        "        filename3 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_adv_' + str(i) + '.npy'\n",
        "        dig_outputs_adv[i] = np.load(filename3)\n",
        "\n",
        "        filename4 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_outputs_noisy' + str(i) + '.npy'\n",
        "        dig_outputs_noisy[i] = np.load(filename4)\n",
        "\n",
        "        filename2 = '/content/gdrive/MyDrive/checkpointCIFAR10/dig_labels_' + str(i) + '.npy'\n",
        "        dig_labels[i] = np.load(filename2)\n",
        "\n",
        "        dig_labels[i] = np.expand_dims(dig_labels[i], axis=1)\n",
        "\n",
        "        data = np.vstack((data, dig_outputs[i]))\n",
        "        data = np.vstack((data, dig_outputs_adv[i]))\n",
        "        data = np.vstack((data, dig_outputs_noisy[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "        labels = np.vstack((labels, dig_labels[i]))\n",
        "\n",
        "    labels = np.squeeze(labels, axis=1)\n",
        "\n",
        "    print(\"labels shape \", labels.shape)\n",
        "    print(\"data shape \", data.shape)\n",
        "\n",
        "    train_data = []\n",
        "    for i in range(len(data)):\n",
        "        train_data.append([data[i], labels[i]])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=128)\n",
        "\n",
        "    my_mlp_model.train()\n",
        "\n",
        "    lr = 0.001\n",
        "    opt = optim.Adam(my_mlp_model.parameters(), lr=lr)\n",
        "    T = 1\n",
        "\n",
        "    my_mlp_model.train()\n",
        "\n",
        "    for epoch in range(150):\n",
        "\n",
        "        total_err = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            data = data.float()\n",
        "            target = target.long()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            output = my_mlp_model(data)\n",
        "            loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_err += (output.max(dim=1)[1] != target).sum().item()\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)] lr: {}\\tLoss: {:.6f}'\n",
        "                      .format(epoch, batch_idx * len(data),\n",
        "                              len(train_loader.dataset),\n",
        "                              100. * batch_idx / len(train_loader),\n",
        "                              lr, loss.data))\n",
        "        print('*******Train Epoch: {} error is {}'.format(epoch + 1, total_err))\n",
        "\n",
        "    my_mlp_model.eval()\n",
        "    print('Save /content/gdrive/MyDrive/checkpointCIFAR10/' + 'MLP_Modell' + '.pth.tar')\n",
        "    state = {'state_dict': my_mlp_model.state_dict()}\n",
        "    filename = '/content/gdrive/MyDrive/checkpointCIFAR10/' + 'MLP_Modell' + '.pth.tar'\n",
        "    torch.save(state, filename)\n",
        "\n",
        "    my_mlp_model_2 = MLP()\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/MLP_Modell.pth.tar')\n",
        "    my_mlp_model_2.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    my_mlp_model_2.eval()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMoZiuzalHw"
      },
      "source": [
        "if input_a == 4:\n",
        "\n",
        "    norm = Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
        "    preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261], axis=-3)\n",
        "\n",
        "    test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/LeNet_dropout.pth.tar')\n",
        "    model_dropout.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    model_dropout.eval()\n",
        "    model_dropout = model_dropout.to(device)\n",
        "\n",
        "    my_mlp_model_2 = MLP()\n",
        "    ckpt_dropout = torch.load('/content/gdrive/MyDrive/checkpointCIFAR10/MLP_Modell.pth.tar')\n",
        "    my_mlp_model_2.load_state_dict(ckpt_dropout['state_dict'])\n",
        "    my_mlp_model_2.eval()\n",
        "    my_mlp_model_2 = my_mlp_model_2.to(device)\n",
        "\n",
        "\n",
        "    print(\"Chose attack type: \\nDeepfool (1)\\nFGSM  (2)\\nBIM  (3)\\nCW  (4)\\nPGD  (5)\\n\")\n",
        "\n",
        "    input_c = int(input())\n",
        "\n",
        "    print(\"Enter epsilon value : \\n\")\n",
        "\n",
        "    eps = float(input())\n",
        "    eps_str = str(int((eps + 0.0000001) * 100))\n",
        "\n",
        "    if input_c == 1:\n",
        "        attack = LinfDeepFoolAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"Deepfool\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 2:\n",
        "        attack = LinfFastGradientAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"FGSM\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 3:\n",
        "        attack = LinfBasicIterativeAttack()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"BIM\"\n",
        "        eps_noisy = eps\n",
        "    elif input_c == 4:\n",
        "\n",
        "        if eps == 0.02:\n",
        "            eps = 0.532 #############################################################\n",
        "            eps_noisy = 0.02\n",
        "        if eps == 0.03:\n",
        "            eps = 0.798 #############################################################\n",
        "            eps_noisy = 0.03 \n",
        "        if eps == 0.04:\n",
        "            eps = 1.064 #############################################################\n",
        "            eps_noisy = 0.04 \n",
        "        print(eps)\n",
        "        attack = L2CarliniWagnerAttack(steps=1000)\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"CW\"\n",
        "    elif input_c == 5:\n",
        "        attack = LinfPGD()\n",
        "        fmodel = PyTorchModel(model_dropout, bounds=(0, 1))\n",
        "        attack_type = \"PGD\"\n",
        "        eps_noisy = eps\n",
        "\n",
        "    print(\"Chosen attack type is \", attack_type)\n",
        "    print(\"Chosen epsilon is \", eps)\n",
        "\n",
        "    print(\"Prepared data will be stored at: \")\n",
        "    print(f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\")\n",
        "\n",
        "    print(\"Beginning time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    first_time = datetime.datetime.now()\n",
        "\n",
        "    al_clean_tensor = torch.empty(0)\n",
        "    ep_clean_tensor = torch.empty(0)\n",
        "    sc_clean_tensor = torch.empty(0)\n",
        "    ent_clean_tensor = torch.empty(0)\n",
        "    preds_clean_tensor = torch.empty(0)\n",
        "    distances_clean_tensor = torch.empty(0)\n",
        "\n",
        "    al_noisy_tensor = torch.empty(0)\n",
        "    ep_noisy_tensor = torch.empty(0)\n",
        "    sc_noisy_tensor = torch.empty(0)\n",
        "    ent_noisy_tensor = torch.empty(0)\n",
        "    preds_noisy_tensor = torch.empty(0)\n",
        "    distances_noisy_tensor = torch.empty(0)\n",
        "\n",
        "    al_dirty_tensor = torch.empty(0)\n",
        "    ep_dirty_tensor = torch.empty(0)\n",
        "    sc_dirty_tensor = torch.empty(0)\n",
        "    ent_dirty_tensor = torch.empty(0)\n",
        "    preds_dirty_tensor = torch.empty(0)\n",
        "    distances_dirty_tensor = torch.empty(0)\n",
        "\n",
        "    preds_clean_tensor = preds_clean_tensor.to(device)\n",
        "    preds_noisy_tensor = preds_noisy_tensor.to(device)\n",
        "    preds_dirty_tensor = preds_dirty_tensor.to(device)\n",
        "\n",
        "\n",
        "    for test_images, test_labels in test_loader:\n",
        "\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        model_dropout.eval()\n",
        "        sample_image = test_images\n",
        "        sample_label = test_labels\n",
        "        outputs = model_dropout(test_images)\n",
        "        preds = outputs.max(dim=1)[1]\n",
        "        corrects = (preds == test_labels)\n",
        "        sample_image = sample_image[corrects]\n",
        "        sample_label = sample_label[corrects]\n",
        "        preds = preds[corrects]\n",
        "        preds = preds.to(device)\n",
        "\n",
        "        al_clean, ep_clean, sc_clean, ent_clean = predict_uncertainties(model_dropout, sample_image, 50)\n",
        "\n",
        "\n",
        "        al_clean_tensor = torch.cat([al_clean_tensor, al_clean])\n",
        "        ep_clean_tensor = torch.cat([ep_clean_tensor, ep_clean])\n",
        "        sc_clean_tensor = torch.cat([sc_clean_tensor, sc_clean])\n",
        "        ent_clean_tensor = torch.cat([ent_clean_tensor, ent_clean])\n",
        "        preds_clean_tensor = torch.cat([preds_clean_tensor, preds])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_clean = model_dropout.last_hidden_layer_output(sample_image).detach().cpu().numpy()\n",
        "\n",
        "        distances_clean = calculate_distance(my_mlp_model_2, preds, last_hidden_layer_outputs_clean)\n",
        "\n",
        "        distances_clean_tensor = torch.cat([distances_clean_tensor, distances_clean])\n",
        "\n",
        "#########################\n",
        "\n",
        "        image_noisy = noise(sample_image, eps_noisy, 0, 1)\n",
        "\n",
        "        al_noisy, ep_noisy, sc_noisy, ent_noisy = predict_uncertainties(model_dropout, image_noisy, 50)\n",
        "\n",
        "        al_noisy_tensor = torch.cat([al_noisy_tensor, al_noisy])\n",
        "        ep_noisy_tensor = torch.cat([ep_noisy_tensor, ep_noisy])\n",
        "        sc_noisy_tensor = torch.cat([sc_noisy_tensor, sc_noisy])\n",
        "        ent_noisy_tensor = torch.cat([ent_noisy_tensor, ent_noisy])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        outputs_noisy = model_dropout(image_noisy)\n",
        "        preds_noisy = outputs_noisy.max(dim=1)[1]\n",
        "\n",
        "        preds_noisy_tensor = torch.cat([preds_noisy_tensor, preds_noisy])\n",
        "\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_noisy = model_dropout.last_hidden_layer_output(image_noisy).detach().cpu().numpy()\n",
        "\n",
        "        distances_noisy = calculate_distance(my_mlp_model_2, preds_noisy, last_hidden_layer_outputs_noisy)\n",
        "\n",
        "        distances_noisy_tensor = torch.cat([distances_noisy_tensor, distances_noisy])\n",
        "\n",
        "#########################\n",
        "\n",
        "        raw_advs, clipped_advs, success = attack(fmodel, sample_image, sample_label, epsilons=[eps])\n",
        "        image_dirty = torch.tensor(clipped_advs[0])\n",
        "\n",
        "        al_dirty, ep_dirty, sc_dirty, ent_dirty = predict_uncertainties(model_dropout, image_dirty, 50)\n",
        "\n",
        "        al_dirty_tensor = torch.cat([al_dirty_tensor, al_dirty])\n",
        "        ep_dirty_tensor = torch.cat([ep_dirty_tensor, ep_dirty])\n",
        "        sc_dirty_tensor = torch.cat([sc_dirty_tensor, sc_dirty])\n",
        "        ent_dirty_tensor = torch.cat([ent_dirty_tensor, ent_dirty])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        outputs_dirty = model_dropout(image_dirty)\n",
        "        preds_dirty = outputs_dirty.max(dim=1)[1]\n",
        "\n",
        "        preds_dirty_tensor = torch.cat([preds_dirty_tensor, preds_dirty])\n",
        "\n",
        "        model_dropout.eval()\n",
        "        with torch.no_grad():\n",
        "            last_hidden_layer_outputs_dirty = model_dropout.last_hidden_layer_output(image_dirty).detach().cpu().numpy()\n",
        "\n",
        "        distances_dirty = calculate_distance(my_mlp_model_2, preds_dirty, last_hidden_layer_outputs_dirty)\n",
        "\n",
        "        distances_dirty_tensor = torch.cat([distances_dirty_tensor, distances_dirty])\n",
        "\n",
        "    #########################\n",
        "\n",
        "    print(\"PREPARING CLEAN DATA....\")\n",
        "\n",
        "    al_clean_tensor, ep_clean_tensor, sc_clean_tensor, ent_clean_tensor = al_clean_tensor.cpu().numpy(), ep_clean_tensor.cpu().numpy(), sc_clean_tensor.cpu().numpy(), ent_clean_tensor.cpu().numpy()\n",
        "    \n",
        "    zero_clean_tensor = np.zeros_like(al_clean_tensor)\n",
        "\n",
        "    distances_clean_tensor = distances_clean_tensor.cpu().numpy()\n",
        "\n",
        "    preds_clean_tensor = preds_clean_tensor.cpu().numpy()\n",
        "\n",
        "    al_clean_tensor = al_clean_tensor.reshape(al_clean_tensor.shape[0], 1)\n",
        "    ep_clean_tensor = ep_clean_tensor.reshape(ep_clean_tensor.shape[0], 1)\n",
        "    sc_clean_tensor = sc_clean_tensor.reshape(sc_clean_tensor.shape[0], 1)\n",
        "    ent_clean_tensor = ent_clean_tensor.reshape(ent_clean_tensor.shape[0], 1)\n",
        "    zero_clean_tensor = zero_clean_tensor.reshape(zero_clean_tensor.shape[0], 1)\n",
        "    preds_clean_tensor = preds_clean_tensor.reshape(preds_clean_tensor.shape[0], 1)\n",
        "    distances_clean_tensor = distances_clean_tensor.reshape(distances_clean_tensor.shape[0],1)\n",
        "\n",
        "    clean_tensor_all = np.concatenate((al_clean_tensor,ep_clean_tensor,sc_clean_tensor,ent_clean_tensor,preds_clean_tensor,distances_clean_tensor,zero_clean_tensor),axis=1)\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING NOISY DATA....\")\n",
        "\n",
        "    al_noisy_tensor, ep_noisy_tensor, sc_noisy_tensor, ent_noisy_tensor = al_noisy_tensor.cpu().numpy(), ep_noisy_tensor.cpu().numpy(), sc_noisy_tensor.cpu().numpy(), ent_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    zero_noisy_tensor = np.zeros_like(al_noisy_tensor)\n",
        "\n",
        "    distances_noisy_tensor = distances_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    preds_noisy_tensor = preds_noisy_tensor.cpu().numpy()\n",
        "\n",
        "    al_noisy_tensor = al_noisy_tensor.reshape(al_noisy_tensor.shape[0], 1)\n",
        "    ep_noisy_tensor = ep_noisy_tensor.reshape(ep_noisy_tensor.shape[0], 1)\n",
        "    sc_noisy_tensor = sc_noisy_tensor.reshape(sc_noisy_tensor.shape[0], 1)\n",
        "    ent_noisy_tensor = ent_noisy_tensor.reshape(ent_noisy_tensor.shape[0], 1)\n",
        "    zero_noisy_tensor = zero_noisy_tensor.reshape(zero_noisy_tensor.shape[0], 1)\n",
        "    preds_noisy_tensor = preds_noisy_tensor.reshape(preds_noisy_tensor.shape[0], 1)\n",
        "    distances_noisy_tensor = distances_noisy_tensor.reshape(distances_noisy_tensor.shape[0],1)\n",
        "\n",
        "\n",
        "    noisy_tensor_all = np.concatenate((al_noisy_tensor,ep_noisy_tensor,sc_noisy_tensor,ent_noisy_tensor,preds_noisy_tensor,distances_noisy_tensor,zero_noisy_tensor),axis=1)\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print(\"PREPARING DIRTY DATA....\")\n",
        "\n",
        "    al_dirty_tensor, ep_dirty_tensor, sc_dirty_tensor, ent_dirty_tensor = al_dirty_tensor.cpu().numpy(), ep_dirty_tensor.cpu().numpy(), sc_dirty_tensor.cpu().numpy(), ent_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    ones_dirty_tensor = np.ones_like(ep_dirty_tensor)\n",
        "\n",
        "    distances_dirty_tensor = distances_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    preds_dirty_tensor = preds_dirty_tensor.cpu().numpy()\n",
        "\n",
        "    al_dirty_tensor = al_dirty_tensor.reshape(al_dirty_tensor.shape[0], 1)\n",
        "    ep_dirty_tensor = ep_dirty_tensor.reshape(ep_dirty_tensor.shape[0], 1)\n",
        "    sc_dirty_tensor = sc_dirty_tensor.reshape(sc_dirty_tensor.shape[0], 1)\n",
        "    ent_dirty_tensor = ent_dirty_tensor.reshape(ent_dirty_tensor.shape[0], 1)\n",
        "    ones_dirty_tensor = ones_dirty_tensor.reshape(ones_dirty_tensor.shape[0], 1)\n",
        "    preds_dirty_tensor = preds_dirty_tensor.reshape(preds_dirty_tensor.shape[0], 1)\n",
        "    distances_dirty_tensor = distances_dirty_tensor.reshape(distances_dirty_tensor.shape[0],1)\n",
        "\n",
        "\n",
        "    dirty_tensor_all = np.concatenate((al_dirty_tensor,ep_dirty_tensor,sc_dirty_tensor,ent_dirty_tensor,preds_dirty_tensor,distances_dirty_tensor,ones_dirty_tensor),axis=1)\n",
        "\n",
        "    print(\"Done....\")\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(\"epistemic uncertainty clean shape \", ep_clean_tensor.shape)\n",
        "    print(\"distance tensor clean shape \", distances_clean_tensor.shape)\n",
        "    print(\"distance tensor noisy shape \", distances_noisy_tensor.shape)\n",
        "    print(\"distance tensor dirty shape \", distances_dirty_tensor.shape)\n",
        "    print(\"preds tensor dirty shape \", preds_dirty_tensor.shape)\n",
        "    print(\"clean data all shape \", clean_tensor_all.shape)\n",
        "    print(\"noisy data all shape \", noisy_tensor_all.shape)\n",
        "    print(\"dirty data all shape \", dirty_tensor_all.shape)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    all_tensor_all = np.concatenate((clean_tensor_all,noisy_tensor_all,dirty_tensor_all),axis=0)\n",
        "\n",
        "    print(\"shape of all data is: \")\n",
        "    print(all_tensor_all.shape)\n",
        "    print()\n",
        "\n",
        "    np.save(f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\", all_tensor_all)\n",
        "\n",
        "    print(\"For Clean data\")\n",
        "    print(\"Number of features : \", al_clean_tensor.shape[0])\n",
        "\n",
        "    print(\"aleatoric :\", al_clean_tensor.mean())\n",
        "    print(\"epistemic :\", ep_clean_tensor.mean())\n",
        "    print(\"scibilic :\", sc_clean_tensor.mean())\n",
        "    print(\"entropy :\", ent_clean_tensor.mean())\n",
        "    print(\"distance :\", distances_clean_tensor.mean())\n",
        "\n",
        "    print(\"For Noisy data\")\n",
        "    print(\"Number of features : \", al_noisy_tensor.shape[0])\n",
        "\n",
        "\n",
        "    print(\"aleatoric :\", al_noisy_tensor.mean())\n",
        "    print(\"epistemic :\", ep_noisy_tensor.mean())\n",
        "    print(\"scibilic :\", sc_noisy_tensor.mean())\n",
        "    print(\"entropy :\", ent_noisy_tensor.mean())\n",
        "    print(\"distance :\", distances_noisy_tensor.mean())\n",
        "\n",
        "    print(\"For Dirty data\")\n",
        "    print(\"Number of features : \", al_dirty_tensor.shape[0])\n",
        "\n",
        "\n",
        "    print(\"aleatoric :\", al_dirty_tensor.mean())\n",
        "    print(\"epistemic :\", ep_dirty_tensor.mean())\n",
        "    print(\"scibilic :\", sc_dirty_tensor.mean())\n",
        "    print(\"entropy :\", ent_dirty_tensor.mean())\n",
        "    print(\"distance :\", distances_dirty_tensor.mean())\n",
        "    print()\n",
        "\n",
        "    print(\"End time is : \")\n",
        "    print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "    print()\n",
        "\n",
        "    later_time = datetime.datetime.now()\n",
        "    difference = later_time - first_time\n",
        "    seconds_in_day = 24 * 60 * 60\n",
        "    print(\"Duration in minutes and seconds is : \")\n",
        "    print(divmod(difference.days * seconds_in_day + difference.seconds, 60))\n",
        "\n",
        "    print(\"####################################\")\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqJXpAVjcBRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "7b0aa68c-f8f8-45fa-b0f0-2da8a41e65f7"
      },
      "source": [
        "if input_a == 5:\n",
        "\n",
        "    print(\"Chose data attack type: \\nDeepfool (1)\\nFGSM  (2)\\nBIM  (3)\\nCW  (4)\\nPGD  (5)\\n\")\n",
        "\n",
        "    input_c = int(input())\n",
        "\n",
        "    if input_c == 1:\n",
        "        attack_type = \"Deepfool\"\n",
        "    elif input_c == 2:\n",
        "        attack_type = \"FGSM\"\n",
        "    elif input_c == 3:\n",
        "        attack_type = \"BIM\"\n",
        "    elif input_c == 4:\n",
        "        attack_type = \"CW\"\n",
        "    elif input_c == 5:\n",
        "        attack_type = \"PGD\"\n",
        "\n",
        "    directory = '/content/gdrive/MyDrive/checkpointCIFAR10/' + attack_type\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    print(\"Enter epsilon value : \\n\")\n",
        "\n",
        "    eps = float(input())\n",
        "    eps_str = str(int((eps+0.0000001)*100))\n",
        "\n",
        "    print(\"Chosen attack type is \", attack_type)\n",
        "    print(\"Chosen epsilon is \", eps)\n",
        "\n",
        "    train_data = f\"/content/gdrive/MyDrive/checkpointCIFAR10/all_numpy_{attack_type}_0{eps_str}.npy\"\n",
        "    tail = f\"_{attack_type}_0{eps_str}.npy\"\n",
        "\n",
        "\n",
        "    train_data_all_numpy = np.load(train_data)\n",
        "    train_data_all_numpy_shuffled = shuffle(train_data_all_numpy, random_state=0)\n",
        "\n",
        "    cols = [[0], [1], [2], [3], [5], [0, 1, 2, 3, 5]]\n",
        "\n",
        "    fpr_list = [\"fpr_aleatoric\", \"fpr_epistemic\", \"fpr_scibilic\", \"fpr_entropy\", \"fpr_distance\", \"fpr_All\"]\n",
        "\n",
        "    tpr_list = [\"tpr_aleatoric\", \"tpr_epistemic\", \"tpr_scibilic\", \"tpr_entropy\", \"fpr_distance\", \"tpr_All\"]\n",
        "\n",
        "    roc_auc_list = [\"roc_auc_aleatoric\", \"roc_auc_epistemic\", \"roc_auc_scibilic\", \"roc_auc_entropy\", \"roc_auc_distance\", \"roc_auc_All\"]\n",
        "\n",
        "    legend_label = ['Aleatoric', 'Epistemic', 'Scibilic', 'Entropy', 'Distance', 'All']\n",
        "\n",
        "    for i,c in enumerate(cols):\n",
        "\n",
        "        col_idx = np.array(c)\n",
        "\n",
        "        X_train = train_data_all_numpy_shuffled[:, col_idx]\n",
        "        y_train = train_data_all_numpy_shuffled[:, -1]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "\n",
        "        logisticRegr = LogisticRegressionCV()\n",
        "        lr = logisticRegr.fit(X_train, y_train)\n",
        "\n",
        "        probs = lr.predict_proba(X_train)\n",
        "        preds = probs[:, 1]\n",
        "\n",
        "        fpr, tpr, threshold = metrics.roc_curve(y_train, preds)\n",
        "\n",
        "        roc_auc = []\n",
        "        roc_auc.append(metrics.auc(fpr, tpr))\n",
        "\n",
        "        fpr = np.array(fpr)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + fpr_list[i] + tail, fpr)\n",
        "\n",
        "        tpr = np.array(tpr)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + tpr_list[i] + tail, tpr)\n",
        "\n",
        "        roc_auc = np.array(roc_auc)\n",
        "        np.save(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + roc_auc_list[i] + tail, roc_auc)\n",
        "\n",
        "    cols = [[0], [1], [2], [3], [5], [0, 1, 2, 3, 5]]\n",
        "\n",
        "    fpr_list = [\"fpr_aleatoric\", \"fpr_epistemic\", \"fpr_scibilic\", \"fpr_entropy\", \"fpr_distance\", \"fpr_All\"]\n",
        "\n",
        "    tpr_list = [\"tpr_aleatoric\", \"tpr_epistemic\", \"tpr_scibilic\", \"tpr_entropy\", \"fpr_distance\", \"tpr_All\"]\n",
        "\n",
        "    roc_auc_list = [\"roc_auc_aleatoric\", \"roc_auc_epistemic\", \"roc_auc_scibilic\", \"roc_auc_entropy\", \"roc_auc_distance\", \"roc_auc_All\"]\n",
        "\n",
        "    legend_label = ['Aleatoric', 'Epistemic', 'Scibilic', 'Entropy', 'Distance', 'All']\n",
        "\n",
        "    for i,c in enumerate(cols):\n",
        "        lw = 2\n",
        "        fpr = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + fpr_list[i] + tail)\n",
        "        tpr = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + tpr_list[i] + tail)\n",
        "        roc_auc = np.load(\"/content/gdrive/MyDrive/checkpointCIFAR10/\" + attack_type + \"/\" + roc_auc_list[i] + tail)[0]\n",
        "\n",
        "        plt.plot(fpr, tpr,lw=lw, label='%s (area = %0.2f)' % (legend_label[i], roc_auc))\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('FPR', fontsize=14)\n",
        "        plt.ylabel('TPR', fontsize=14)\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.title(f'Under {attack_type} attack with epsilon = {str(eps)}')\n",
        "    plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chose data attack type: \n",
            "Deepfool (1)\n",
            "FGSM  (2)\n",
            "BIM  (3)\n",
            "CW  (4)\n",
            "PGD  (5)\n",
            "\n",
            "3\n",
            "Enter epsilon value : \n",
            "\n",
            "0.04\n",
            "Chosen attack type is  BIM\n",
            "Chosen epsilon is  0.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}